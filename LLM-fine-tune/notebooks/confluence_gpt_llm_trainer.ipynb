{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM8MRkf8Dr94"
      },
      "source": [
        "## Describe your model -> fine-tuned LLaMA 2\n",
        "Adapted froma contribution of  Matt Shumer (https://twitter.com/mattshumer_)\n",
        "\n",
        "The goal of this notebook is to experiment with a new way to make it very easy to build a task-specific model for your use-case.\n",
        "\n",
        "First, use the best GPU available (go to Runtime -> change runtime type)\n",
        "\n",
        "To create your model, just go to the first code cell, and describe the model you want to build in the prompt. Be descriptive and clear.\n",
        "\n",
        "Select a temperature (high=creative, low=precise), and the number of training examples to generate to train the model. From there, just run all the cells.\n",
        "\n",
        "You can change the model you want to fine-tune by changing `model_name` in the `Define Hyperparameters` cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Way3_PuPpIuE"
      },
      "source": [
        "# Data generation step (optional, start for section 2, here is if you want a custom model for other use case)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY-3DvlIpVSl"
      },
      "source": [
        "Write your prompt here. Make it as descriptive as possible!\n",
        "\n",
        "Then, choose the temperature (between 0 and 1) to use when generating data. Lower values are great for precise tasks, like writing code, whereas larger values are better for creative tasks, like writing stories.\n",
        "\n",
        "Finally, choose how many examples you want to generate. The more you generate, a) the longer it takes and b) the more expensive data generation will be. But generally, more examples will lead to a higher-quality model. 100 is usually the minimum to start."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7WKZyxtpUPS"
      },
      "outputs": [],
      "source": [
        "prompt = \"A model that takes in a puzzle-like reasoning-heavy question in English, and responds with a well-reasoned, step-by-step thought out response in Spanish.\"\n",
        "temperature = .4\n",
        "number_of_examples = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1snNou5PrIci"
      },
      "source": [
        "Run this to generate the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuL2UaqlsmBD",
        "outputId": "74446512-59ec-44cf-9a7c-01e6441154ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.25.0-py3-none-any.whl (312 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/312.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m307.2/312.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rdsd82ngpHCG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import random\n",
        "\n",
        "openai.api_key = \"YOUR KEY HERE\"\n",
        "\n",
        "def generate_example(prompt, prev_examples, temperature=.5):\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"You are generating data which will be used to train a machine learning model.\\n\\nYou will be given a high-level description of the model we want to train, and from that, you will generate data samples, each with a prompt/response pair.\\n\\nYou will do so in this format:\\n```\\nprompt\\n-----------\\n$prompt_goes_here\\n-----------\\n\\nresponse\\n-----------\\n$response_goes_here\\n-----------\\n```\\n\\nOnly one prompt/response pair should be generated per turn.\\n\\nFor each turn, make the example slightly more complex than the last, while ensuring diversity.\\n\\nMake sure your samples are unique and diverse, yet high-quality and complex enough to train a well-performing model.\\n\\nHere is the type of model we want to train:\\n`{prompt}`\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    if len(prev_examples) > 0:\n",
        "        if len(prev_examples) > 10:\n",
        "            prev_examples = random.sample(prev_examples, 10)\n",
        "        for example in prev_examples:\n",
        "            messages.append({\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": example\n",
        "            })\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=1354,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content']\n",
        "\n",
        "# Generate examples\n",
        "prev_examples = []\n",
        "for i in range(number_of_examples):\n",
        "    print(f'Generating example {i}')\n",
        "    example = generate_example(prompt, prev_examples, temperature)\n",
        "    prev_examples.append(example)\n",
        "\n",
        "print(prev_examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC6iJzXjugJ-"
      },
      "source": [
        "We also need to generate a system message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMcfhW6Guh2E"
      },
      "outputs": [],
      "source": [
        "def generate_system_message(prompt):\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "          {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You will be given a high-level description of the model we are training, and from that, you will generate a simple system prompt for that model to use. Remember, you are not generating the system message for data generation -- you are generating the system message to use for inference. A good format to follow is `Given $INPUT_DATA, you will $WHAT_THE_MODEL_SHOULD_DO.`.\\n\\nMake it as concise as possible. Include nothing but the system prompt in your response.\\n\\nFor example, never write: `\\\"$SYSTEM_PROMPT_HERE\\\"`.\\n\\nIt should be like: `$SYSTEM_PROMPT_HERE`.\"\n",
        "          },\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt.strip(),\n",
        "          }\n",
        "        ],\n",
        "        temperature=temperature,\n",
        "        max_tokens=500,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message['content']\n",
        "\n",
        "system_message = generate_system_message(prompt)\n",
        "\n",
        "print(f'The system message is: `{system_message}`. Feel free to re-run this cell if you want a better result.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6BqZ-hjseBF"
      },
      "source": [
        "Now let's put our examples into a dataframe and turn them into a final pair of datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CEdkYeRsdmB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize lists to store prompts and responses\n",
        "prompts = []\n",
        "responses = []\n",
        "\n",
        "# Parse out prompts and responses from examples\n",
        "for example in prev_examples:\n",
        "  try:\n",
        "    split_example = example.split('-----------')\n",
        "    prompts.append(split_example[1].strip())\n",
        "    responses.append(split_example[3].strip())\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'prompt': prompts,\n",
        "    'response': responses\n",
        "})\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print('There are ' + str(len(df)) + ' successfully-generated examples. Here are the first few:')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-8dt5qqtpgM"
      },
      "source": [
        "Split into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXO6WrsgQ81M"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test sets, with 90% in the train set\n",
        "train_df = df.sample(frac=0.9, random_state=42)\n",
        "test_df = df.drop(train_df.index)\n",
        "\n",
        "# Save the dataframes to .jsonl files\n",
        "train_df.to_json('train.jsonl', orient='records', lines=True)\n",
        "test_df.to_json('test.jsonl', orient='records', lines=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAOZzmYqQ9Vd"
      },
      "source": [
        "# ALTERNATIVE. Importing dataset from confluence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlnIpklGRPpT",
        "outputId": "01dbad63-4656-4647-dc23-a0083056236a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (1.0.1)\n",
            "Requirement already satisfied: requests in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (2.31.0)\n",
            "Requirement already satisfied: langchain-community in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (0.0.36)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (0.6.5)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (0.1.48)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (0.1.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-community) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain-community) (2.7.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.48->langchain-community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.48->langchain-community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.48->langchain-community) (2.18.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: langchain in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (0.1.17)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.6.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.0.36)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.1.48)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: atlassian-python-api in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (3.41.11)\n",
            "Requirement already satisfied: deprecated in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (1.2.14)\n",
            "Requirement already satisfied: requests in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (2.31.0)\n",
            "Requirement already satisfied: six in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (1.16.0)\n",
            "Requirement already satisfied: oauthlib in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (2.0.0)\n",
            "Requirement already satisfied: jmespath in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (1.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from atlassian-python-api) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from beautifulsoup4->atlassian-python-api) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from deprecated->atlassian-python-api) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests->atlassian-python-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests->atlassian-python-api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests->atlassian-python-api) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests->atlassian-python-api) (2024.2.2)\n",
            "Requirement already satisfied: lxml in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (5.2.1)\n",
            "Requirement already satisfied: tiktoken in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from tiktoken) (2024.4.28)\n",
            "Requirement already satisfied: requests>=2.26.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: pandas in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: boto3 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (1.34.95)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.95 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from boto3) (1.34.95)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from boto3) (0.10.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.95->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.95->boto3) (2.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/justinjimenez/Documents/Webconnex/confluence and github fine tune/pruebas_confluence/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.95->boto3) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv requests langchain-community\n",
        "!pip install langchain\n",
        "!pip install atlassian-python-api\n",
        "!pip install lxml\n",
        "!pip install tiktoken\n",
        "!pip install pandas\n",
        "!pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K__MJLe_cbm4",
        "outputId": "469d95c2-d37f-4868-ea33-2703c84125ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Received runtime arguments {'space_key': 'EN', 'limit': 1, 'max_pages': 5}. Passing runtime args to `load` is deprecated. Please pass arguments during initialization instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunk 1 Content:\n",
            "Welcome to the Engineering Portal Search: large Search Favorite Pages Product Domains On-Call Responsibilities Core Values Coding Style Guides Key Links https://app.gusto.com/login https://login.okta.com/ https://www.datadoghq.com/ https://github.com/webconnex Recently updated page, comment, blogpost, spacedesc 10 true concise Other Spaces of Interest: Infrastructure Space Enterprise Foundation Team Space App Development Space Product Red Squadron Blizzard Force\n",
            "---\n",
            "Metadata:\n",
            "{'title': 'Engineering', 'id': '24969371', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/overview', 'when': '2023-10-09T04:46:45.355Z'}\n",
            "==================================================\n",
            "\n",
            "Chunk 2 Content:\n",
            "While this is a living document that will always be changing, as of right now this it is considered Complete Green true and can/should be referenced. Webconnex draws it's style guides from the Golang community. We rely heavily on the following documents. Effective Go Effective Go gives tips for writing clear, idiomatic Go code. Review Comments Review Comments is a supplemental guide to Effective Go and contains a collection of common comments made during reviews of Go code. This is a laundry list of common\n",
            "---\n",
            "Metadata:\n",
            "{'title': 'GoLang (Go)', 'id': '40894467', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/40894467', 'when': '2023-05-16T22:42:52.344Z'}\n",
            "==================================================\n",
            "\n",
            "Chunk 3 Content:\n",
            "list of common mistakes, not a style guide. As a team, we've standardized on specific rules detailed below: Yoda Condition We have chosen not to use Yoda notation , as it impairs readability and offers little value within the Go code. The compile spots and blocks inside conditional rendering the benefits negligible. Migration The original 4.0 API code followed Yoda Conditions, so a migration path is necessary.  New code should be written in standard notation and old code should be converted in SMALL chunks\n",
            "---\n",
            "Metadata:\n",
            "{'title': 'GoLang (Go)', 'id': '40894467', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/40894467', 'when': '2023-05-16T22:42:52.344Z'}\n",
            "==================================================\n",
            "\n",
            "Chunk 4 Content:\n",
            "in SMALL chunks to prevent merge conflicts. Ideally, old code should be updated when you are sure nothing else is in active development of that file. PLEASE DO NOT DO A FIND AND REPLACE large sections. If Statement Initialization If statements should only be used to initialize functions when a single error or bool is used from the function in question. Otherwise, the function should be called prior to the if statement. Examples Inlined Separated Struct Comments No full line comments should exist between\n",
            "---\n",
            "Metadata:\n",
            "{'title': 'GoLang (Go)', 'id': '40894467', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/40894467', 'when': '2023-05-16T22:42:52.344Z'}\n",
            "==================================================\n",
            "\n",
            "Chunk 5 Content:\n",
            "exist between struct field designations. To do so vertically dealigns field components with the formatter we currently use. Example Struct with Unaligned Field Components Gorm Select() Gorm allows us to select specific fields when performing queries.  This can be used for performance improvements.  When selecting a single record, we should not use the `.Select()` chained method as it is an over-optimization.  Any performance gains are canceled by more clever code and cost of maintenance. In general, using\n",
            "---\n",
            "Metadata:\n",
            "{'title': 'GoLang (Go)', 'id': '40894467', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/40894467', 'when': '2023-05-16T22:42:52.344Z'}\n",
            "==================================================\n",
            "\n",
            "Chunk 6 Content:\n",
            "In general, using the `.Select()` can be useful when selecting multiple records from the following models `Page`, `Order`, `Registrant` since they can contain very large blob payloads.  This is particularly useful when only a few columns are needed such as the `id`. Examples Single Record Examples) Multiple Records Linting All code should be processed through a linter; fixing common mechanical errors and ensuring common styles across go packages. We've chosen Lint as the Webconnex standard. Most developers\n",
            "---\n",
            "Metadata:\n",
            "{'title': 'GoLang (Go)', 'id': '40894467', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/40894467', 'when': '2023-05-16T22:42:52.344Z'}\n",
            "==================================================\n",
            "\n",
            "Chunk 7 Content:\n",
            "Most developers run goplus , visualstudio or similar editor plugins which automatically run linting upon save. Coverage & Tests All code should have adequate test coverage to provide documentation and provide a minimum level of reliability. While there is no set minimum coverage level, developers should strive for high coverage. Additionally, PR reviews can always ask for additional tests if they feel coverage is lacking or additional clarification is needed. Vendoring All Go projects should have\n",
            "---\n",
            "Metadata:\n",
            "{'title': 'GoLang (Go)', 'id': '40894467', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/40894467', 'when': '2023-05-16T22:42:52.344Z'}\n",
            "==================================================\n",
            "\n",
            "Chunk 8 Content:\n",
            "should have dependency control, using Go Mods.\n",
            "---\n",
            "Metadata:\n",
            "{'title': 'GoLang (Go)', 'id': '40894467', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/40894467', 'when': '2023-05-16T22:42:52.344Z'}\n",
            "==================================================\n",
            "\n",
            "Chunk 9 Content:\n",
            "Because the current team structure consists of remote members, the responsiveness and quality of communication is extremely important to keeping a healthy, high functioning team. General Slack Almost all general communication takes place in Slack . We have a general #development channel as well as other specialized channels built around integrations. When in slack use @person or @group as much as possible to get people's attention. If some sends a message to you or needing your response please take a moment\n",
            "---\n",
            "Metadata:\n",
            "{'title': 'Communication', 'id': '40894484', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/40894484/Communication', 'when': '2018-06-29T14:13:37.039Z'}\n",
            "==================================================\n",
            "\n",
            "Chunk 10 Content:\n",
            "take a moment to acknowledge them and let them know when they might be able to chat/meet with you. Email Since the inception of Slack, almost all of our email communication involves customers. Please be prompt with your replies even if you aren't addressing the problem right always. Zoom Most of team or group meetings and one-on-ones happen on Zoom. Please have this open and ready during the day as your availability allows. Project Management All of our development project management happens in GitHub\n",
            "---\n",
            "Metadata:\n",
            "{'title': 'Communication', 'id': '40894484', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/40894484/Communication', 'when': '2018-06-29T14:13:37.039Z'}\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from langchain.document_loaders import ConfluenceLoader\n",
        "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
        "# Intenta importar BeautifulSoup y lxml, maneja la excepción si lxml no está instalado\n",
        "try:\n",
        "    from bs4 import BeautifulSoup\n",
        "except ImportError as e:\n",
        "    raise ImportError(\"Por favor, asegúrate de que la librería 'lxml' está instalada. Usa: pip install lxml\") from e\n",
        "\n",
        "\n",
        "# Configuración de variables de entorno\n",
        "sys.path.append('../')\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "# Configuración de Confluence\n",
        "CONFLUENCE_URL = os.getenv(\"CONFLUENCE_URL\")\n",
        "CONFLUENCE_API_KEY = os.getenv(\"CONFLUENCE_API_KEY\")\n",
        "CONFLUENCE_USERNAME = os.getenv(\"CONFLUENCE_USERNAME\")\n",
        "CONFLUENCE_SPACE_KEY = os.getenv(\"CONFLUENCE_SPACE_KEY\")\n",
        "\n",
        "# Cargar documentos desde Confluence\n",
        "loader = ConfluenceLoader(\n",
        "    url=CONFLUENCE_URL,\n",
        "    username=CONFLUENCE_USERNAME,\n",
        "    api_key=CONFLUENCE_API_KEY\n",
        ")\n",
        "docs = loader.load(\n",
        "    space_key=CONFLUENCE_SPACE_KEY,\n",
        "    # limit=1,\n",
        "    # max_pages=5,\n",
        "    keep_markdown_format=True\n",
        ")\n",
        "\n",
        "# Dividir documentos basados en cabeceras Markdown\n",
        "def split_markdown_documents(docs):\n",
        "    # Markdown\n",
        "    headers_to_split_on = [\n",
        "            (\"#\", \"Title 1\"),\n",
        "            (\"##\", \"Subtitle 1\"),\n",
        "            (\"###\", \"Subtitle 2\"),\n",
        "    ]\n",
        "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
        "\n",
        "    # Split based on markdown and add original metadata\n",
        "    md_docs = []\n",
        "    for doc in docs:\n",
        "        md_doc = markdown_splitter.split_text(doc.page_content)\n",
        "        for i in range(len(md_doc)):\n",
        "            md_doc[i].metadata = md_doc[i].metadata | doc.metadata\n",
        "        md_docs.extend(md_doc)\n",
        "\n",
        "    # RecursiveTextSplitter\n",
        "    # Chunk size big enough\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=512,\n",
        "        chunk_overlap=20,\n",
        "        separators=[r\"\\n\\n\", r\"\\n\", r\"(?<=\\. )\", \" \", \"\"]\n",
        "    )\n",
        "\n",
        "    splitted_docs = splitter.split_documents(md_docs)\n",
        "    return splitted_docs\n",
        "\n",
        "# Proceso completo\n",
        "texts = split_markdown_documents(docs)\n",
        "\n",
        "# Imprimir los primeros 10 chunks\n",
        "def pretty_print(chunks, limit=10):\n",
        "    for i, chunk in enumerate(chunks[:limit]):\n",
        "        print(f\"Chunk {i+1} Content:\\n{chunk.page_content}\\n---\\nMetadata:\\n{chunk.metadata}\\n{'='*50}\\n\")\n",
        "\n",
        "# pretty_print(texts) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6Lzh3-uCRV8j"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "from langchain_community.chat_models import BedrockChat\n",
        "\n",
        "# Configuración de AWS\n",
        "session = boto3.Session(profile_name='881184462287-/okta-admin-user')\n",
        "bedrock_client = session.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
        "\n",
        "# Función para generar preguntas usando AWS Bedrock\n",
        "def generate_question(chunk_text, metadata):\n",
        "    llm = BedrockChat(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", region_name=\"us-east-1\", client=bedrock_client)\n",
        "\n",
        "    # Crear el prompt y configurar el mensaje de usuario\n",
        "    prompt = f\"Consider this text: '{chunk_text}' and this metadata '{metadata}'. What would be an appropriate question that a developer would formulate for which this text is an answer? return only the question no more text nedeed\"\n",
        "    user_messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    try:\n",
        "        response = llm.invoke(user_messages)\n",
        "        # Extracción del contenido de la respuesta, asegurándose de obtener el texto de la respuesta\n",
        "        question = response.content\n",
        "        return question\n",
        "    except Exception as e:\n",
        "        print(f\"Error during API call: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "#chunk_text = \"The Python Software Foundation manages the open-source licensing for Python version 3.7 and later.\"\n",
        "#question = generate_question(chunk_text)\n",
        "#print(\"Generated Question:\", question)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANOkNXHlRbTD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Lista para almacenar los pares prompt-response junto con metadata\n",
        "prompt_response_pairs = []\n",
        "\n",
        "# Procesar cada documento en el conjunto de textos\n",
        "for document in texts:\n",
        "    chunk_text = document.page_content  # Asumiendo que el texto está en el atributo 'page_content'\n",
        "    metadata = document.metadata if hasattr(document, 'metadata') else {}\n",
        "    try:\n",
        "        question = generate_question(chunk_text, metadata)\n",
        "        # question = \"holis\"\n",
        "        if question:  # Asegurarse de que la pregunta fue generada\n",
        "            prompt_response_pairs.append({\n",
        "                'prompt': question,\n",
        "                'response': chunk_text,\n",
        "                'metadata': metadata\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(f\"Error al generar pregunta para el chunk: {e}\")\n",
        "\n",
        "# Crear un DataFrame con los datos recogidos\n",
        "df = pd.DataFrame(prompt_response_pairs)\n",
        "\n",
        "# Mostrar los primeros registros para verificar\n",
        "print(df.head())\n",
        "\n",
        "# Opcional: guardar el DataFrame como un archivo CSV\n",
        "df.to_csv(\"prompt_response_pairs.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "gxJeqn5O6Pty",
        "outputId": "8674a414-335a-45d2-b726-aaac59c18900"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 570,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 570,\n        \"samples\": [\n          \"Why did the payment outage occur on March 28th, 2024 that led to double charged payments?\",\n          \"What are the Python style guide recommendations for naming conventions, file naming, function length, and type annotations?\",\n          \"How do I extract the accountId from a path with subpaths?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 568,\n        \"samples\": [\n          \"top Feature The BoxOffice app gives our customers the ability to: - Sell tickets and merchandise onsite - Void transactions made within that session - Check in tickets. - Print Tickets - Send Tickets via Text - Enable tickets for Mobile Pay Pass Availability Apple Android Known Issues Major Errors If a field is added into Director and BoxOffice is not updated with that newest version, BoxOffice will completely crash if the page being loaded uses that new field. Errors that aren\\u2019t actually errors Especially for Shebang era network calls (see the API section below), these don\\u2019t always give back the most helpful status codes and hence often will return 500\\u2019s even though the server didn\\u2019t actually have an error like this. Logging out of a square account in the settings screen does not work in dev env We have no way with square transactions/swippers to do a test charge without actually charging a real card (so you should just set your ticket price to $1) then refund yourself from the Square Dashboard When using a Magtech Swipper on a non-production page with a testing gateway the network call will actually throw and error. Instead, to test a transaction select the input manually option or move to a production page with a live testing gateway. This means that the card you use will be charged! See more details about how tokenization works below. Details Key functionality Processing Credit Card Transactions Square Requires account and Square swipper The transaction is handled completely by Square. We only send order details back to our servers. While Square transactions can be processed on dev environments, logging out of a Square account is only available on release and production environments Magtech Requires a magtech swipper and is used by the majority of our customers. See how Tokenization works below. Magtech utilizes the payment gateways WBX regualarly offers For Adyen transactions, we allow the civilian to input only thier zip code. Because of this, we inject a fake email within the app, that\\u2019s later removed before it\\u2019s stored in our database. Manages a cash box to generate cashier sale reports This feature allows our customers to: Settle their books, especially when a volunteer tries to steal cash Understand which entrances at their event had the most volume Gauge the number of staff needed for future events Prints tickets via Boca Printer or a Star Micronics printer Enables customers to view and void recent orders made on the app Allows customers to check in civilians or text them their ticket Page Builder allows custom BoxOffice overrides for pricing/fees In BoxOffice we charge $0.49 for each ticket verses via Bacon we charge $0.99 Allows customers to purchase tickets on Reserved Seating venues. Tokenization Magetch swippers have our TokenEx private key within it so that when a card is swipped, the details are immediately encrypted before given to the device (iPhone, iPad, etc). Once given to the device, BoxOffice sends the encrypted card data to TokenEx where they give us a billing token. Then BoxOffice takes this billing token and performs a registration for a civilian. Because of this, BoxOffice never actually handles a plaintext CC number. Our dev environments have a completely different TokenEx private key, however, the majority of our swippers availible are only keyed to our production TokenEx vault. This means that: Magtech swippers will only succeed when the environment is set to the production and the transaction is against a live gateway (instead of a tester). Technical Documents Note: for some reason it\\u2019s not letting me add lucid chart to here. Link is below Lucid chart: Box Office App | Lucidchart Client Side Below is a brief layout of the file structure for BoxOffice app .swift\\n    \\u2514\\u2500\\u2500 Controls\\n    \\u2514\\u2500\\u2500 Extensions\\n    \\u2502   \\u2514\\u2500\\u2500 .swift\\n    \\u2514\\u2500\\u2500 Interfaces\\n    \\u251c\\u2500\\u2500 Networking\\n    \\u2502   \\u2514\\u2500\\u2500 BONetworking.swift\\n\\u2514\\u2500\\u2500 Printers\\n\\u2514\\u2500\\u2500 CardReaders\\n\\u2514\\u2500\\u2500 UI\\n    \\u251c\\u2500\\u2500 \\u2502   \\u2514\\u2500\\u2500 ViewController.swift\\n    \\u2502   \\u2514\\u2500\\u2500 ViewModel.swift\\n    \\u2502   \\u2514\\u2500\\u2500 Model.swift]]> UI Layer Info BoxOffice uses what\\u2019s called a Model View Controller (MVC) layout which is an industry standard for mobile apps. This means that within the UI folder for any single view there are three files(see above). The ViewController is where all UI components live and are given dynamic data which usually comes from the ViewModel and Model . However, there is one other important file when diagnosing UI items which is the Main.storyboard (in the root of the Boxoffice folder). This essentially defines all major UI components for any given view, while you can think of the ViewController.swift as the file that initializes them. Network Layer Info All network calls are made within Common/Networking/BONetworking.swift . When a network call errors out, the logging occurs in this file. Most network calls are invoked like this - for this example we will use the{'title': 'Boxoffice App', 'id': '2124447786', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/2124447786/Boxoffice+App', 'when': '2024-03-27T16:44:54.338Z'}\",\n          \"What this is: What to do: DB Cleanup:{'title': 'Fail Over a Bricked Database', 'id': '254640212', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/254640212/Fail+Over+a+Bricked+Database', 'when': '2019-11-26T08:47:58.815Z'}\",\n          \"Our general deploy flow is outlined below and can also be viewed here . QA For the larger projects, we will have both the product team and our QA engineer(s) involved; that said, the engineers are always responsible for taking the first pass at QA to ensure the deployment works and the feature passes the requirements. QA and Product will identify edge cases and other bugs and work with the team to determine prioritizations of those bugs and edge cases. For smaller hotfixes/refactors, the QA responsibility falls mainly on the engineer to check their work and check for regressions. The QA team can help with E2E tests as needed. Deployments We try to deploy at least once a week. Deployments will occasionally increase during product launches and for hotfixes as required for production support. The deployment flow for a feature will require that feature code gets built at least three times. Even hotfixes will likely go through three reviews, at the very least two. The first tests will take place in one of the dev environments. We currently have two environments for dev testing on our development Kubernetes cluster. The project you are working on will determine which one you are using. We can scale these up and down as needed. After testing and approval, the code can is merged into develop. We usually will batch several merges to develop into a release candidate. Once a release is ready a new branch will be created off of develop and deployed to the release environment for final testing. Pending approval, a new PR is created to master , and from master , a tagged version will be created, which will fire off a CI/CD pipeline in Codefresh and deploy to production. Production Approvals The CI/CD Pipeline for production/tagged builds will require that a manual approval process for each batch of services is executed either through Codefresh or in the #deployments slack channel.{'title': 'QA/Deployment Processes', 'id': '852525065', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/852525065', 'when': '2023-03-28T17:27:17.500Z'}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 413,\n        \"samples\": [\n          \"{'title': 'Changelog and Updates', 'id': '2376302594', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/2376302594/Changelog+and+Updates', 'when': '2024-04-29T21:33:52.271Z'}\",\n          \"{'title': 'Manually Registering a Sole Proprietorship in Twilio', 'id': '2325708810', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/2325708810/Manually+Registering+a+Sole+Proprietorship+in+Twilio', 'when': '2024-03-18T20:19:35.453Z'}\",\n          \"{'title': 'Things to do when phishing campaign is identified', 'id': '2379776051', 'source': 'https://webconnex.atlassian.net/wiki/spaces/EN/pages/2379776051/Things+to+do+when+phishing+campaign+is+identified', 'when': '2024-04-18T00:02:40.371Z'}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ceeedff0-2348-4164-af7f-de3c2590ef12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What information and links are available on th...</td>\n",
              "      <td>Welcome to the Engineering Portal Search: larg...</td>\n",
              "      <td>{'title': 'Engineering', 'id': '24969371', 'so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the coding standards and best practic...</td>\n",
              "      <td>While this is a living document that will alwa...</td>\n",
              "      <td>{'title': 'GoLang (Go)', 'id': '40894467', 'so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How do we communicate and collaborate effectiv...</td>\n",
              "      <td>Because the current team structure consists of...</td>\n",
              "      <td>{'title': 'Communication', 'id': '40894484', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the best practices and guidelines for...</td>\n",
              "      <td>This document is a place where we can note and...</td>\n",
              "      <td>{'title': 'Best Practices and Guidelines', 'id...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the coding style guidelines and best ...</td>\n",
              "      <td>For the most part we follow idiomatic Golang p...</td>\n",
              "      <td>{'title': 'Coding Style Guides', 'id': '409600...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>How can I modify the API rate limits for an ac...</td>\n",
              "      <td>1 1 false decimal list false Set the API limit...</td>\n",
              "      <td>{'title': 'Public API Runbook', 'id': '2393047...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>Why did the release of the Purchase Protection...</td>\n",
              "      <td>Postmortem summary Postmortem owner Incident d...</td>\n",
              "      <td>{'title': '2024/04/19 - Purchase Protection Ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>What details should be included in a postmorte...</td>\n",
              "      <td>Postmortem summary Postmortem owner Incident d...</td>\n",
              "      <td>{'title': '2024/04/26 - Tickets displaying Pen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>What steps should be taken to address the issu...</td>\n",
              "      <td>refactor of the codebase to improve readabili...</td>\n",
              "      <td>{'title': '2024/04/26 - Tickets displaying Pen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569</th>\n",
              "      <td>Why do we get messages on the #blizzard-force-...</td>\n",
              "      <td>The Problem From time to time we get a message...</td>\n",
              "      <td>{'title': 'Asynq Failed Tasks Runbook', 'id': ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>570 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceeedff0-2348-4164-af7f-de3c2590ef12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ceeedff0-2348-4164-af7f-de3c2590ef12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ceeedff0-2348-4164-af7f-de3c2590ef12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4038ad58-78d7-46ed-a86f-92165b777e80\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4038ad58-78d7-46ed-a86f-92165b777e80')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4038ad58-78d7-46ed-a86f-92165b777e80 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                prompt  \\\n",
              "0    What information and links are available on th...   \n",
              "1    What are the coding standards and best practic...   \n",
              "2    How do we communicate and collaborate effectiv...   \n",
              "3    What are the best practices and guidelines for...   \n",
              "4    What are the coding style guidelines and best ...   \n",
              "..                                                 ...   \n",
              "565  How can I modify the API rate limits for an ac...   \n",
              "566  Why did the release of the Purchase Protection...   \n",
              "567  What details should be included in a postmorte...   \n",
              "568  What steps should be taken to address the issu...   \n",
              "569  Why do we get messages on the #blizzard-force-...   \n",
              "\n",
              "                                              response  \\\n",
              "0    Welcome to the Engineering Portal Search: larg...   \n",
              "1    While this is a living document that will alwa...   \n",
              "2    Because the current team structure consists of...   \n",
              "3    This document is a place where we can note and...   \n",
              "4    For the most part we follow idiomatic Golang p...   \n",
              "..                                                 ...   \n",
              "565  1 1 false decimal list false Set the API limit...   \n",
              "566  Postmortem summary Postmortem owner Incident d...   \n",
              "567  Postmortem summary Postmortem owner Incident d...   \n",
              "568   refactor of the codebase to improve readabili...   \n",
              "569  The Problem From time to time we get a message...   \n",
              "\n",
              "                                              metadata  \n",
              "0    {'title': 'Engineering', 'id': '24969371', 'so...  \n",
              "1    {'title': 'GoLang (Go)', 'id': '40894467', 'so...  \n",
              "2    {'title': 'Communication', 'id': '40894484', '...  \n",
              "3    {'title': 'Best Practices and Guidelines', 'id...  \n",
              "4    {'title': 'Coding Style Guides', 'id': '409600...  \n",
              "..                                                 ...  \n",
              "565  {'title': 'Public API Runbook', 'id': '2393047...  \n",
              "566  {'title': '2024/04/19 - Purchase Protection Ch...  \n",
              "567  {'title': '2024/04/26 - Tickets displaying Pen...  \n",
              "568  {'title': '2024/04/26 - Tickets displaying Pen...  \n",
              "569  {'title': 'Asynq Failed Tasks Runbook', 'id': ...  \n",
              "\n",
              "[570 rows x 3 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"prompt_response_pairs.csv\")\n",
        "df['response'] = df['response'] + df['metadata']\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQxtnePuwQUB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKVAXiENglWP"
      },
      "outputs": [],
      "source": [
        "# Cargar el segundo DataFrame desde otro CSV\n",
        "df_additional = pd.read_csv(\"github - Sheet1-2.csv\")\n",
        "\n",
        "# Fusionar ambos DataFrames\n",
        "df_combined = pd.concat([df, df_additional], ignore_index=True)\n",
        "\n",
        "# Opcional: Eliminar duplicados si es necesario\n",
        "df_combined = df_combined.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "zeV2oSBIgwS0",
        "outputId": "19492369-4d52-4865-f8bb-88a95e963ab8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"582\",\n          \"readme for shebang repo?\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          575,\n          \"6\",\n          \"582\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          413,\n          \"33\",\n          \"570\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-5dc1ac6a-108b-469b-b8ed-127bb7ffad2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>response</th>\n",
              "      <th>metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>582</td>\n",
              "      <td>582</td>\n",
              "      <td>570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>582</td>\n",
              "      <td>575</td>\n",
              "      <td>413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>readme for shebang repo?</td>\n",
              "      <td>Shebang\\n\\nShebang contains various API's used...</td>\n",
              "      <td>{'title': 'Python', 'id': '254509193', 'source...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dc1ac6a-108b-469b-b8ed-127bb7ffad2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5dc1ac6a-108b-469b-b8ed-127bb7ffad2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5dc1ac6a-108b-469b-b8ed-127bb7ffad2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3a22cab4-3317-4e32-b757-16fbc0af4453\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a22cab4-3317-4e32-b757-16fbc0af4453')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3a22cab4-3317-4e32-b757-16fbc0af4453 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                          prompt  \\\n",
              "count                        582   \n",
              "unique                       582   \n",
              "top     readme for shebang repo?   \n",
              "freq                           1   \n",
              "\n",
              "                                                 response  \\\n",
              "count                                                 582   \n",
              "unique                                                575   \n",
              "top     Shebang\\n\\nShebang contains various API's used...   \n",
              "freq                                                    6   \n",
              "\n",
              "                                                 metadata  \n",
              "count                                                 570  \n",
              "unique                                                413  \n",
              "top     {'title': 'Python', 'id': '254509193', 'source...  \n",
              "freq                                                   33  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df_combined.copy()\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpOz2x48_brZ"
      },
      "outputs": [],
      "source": [
        "system_message = \"This model provides proffesional answers that have metadata and URL to refer to the source of the answer to specific questions of  Webconnex employees using the model knowledge, the model answer the question if doesn't know the question it will respond <I don't have the answer>.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbrFgrhG_xYi"
      },
      "source": [
        "# Install necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPG7wEPetFx2"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moVo0led-6tu"
      },
      "source": [
        "# Define Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqfbhUZI-4c_"
      },
      "outputs": [],
      "source": [
        "model_name = \"NousResearch/llama-2-7b-chat-hf\" # use this if you have access to the official LLaMA 2 model \"meta-llama/Llama-2-7b-chat-hf\", though keep in mind you'll need to pass a Hugging Face key argument\n",
        "dataset_name = \"/content/train.jsonl\"\n",
        "new_model = \"llama-2-7b-custom\"\n",
        "lora_r = 64\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "use_4bit = True\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "use_nested_quant = False\n",
        "output_dir = \"./results\"\n",
        "num_train_epochs = 1\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "per_device_train_batch_size = 4\n",
        "per_device_eval_batch_size = 4\n",
        "gradient_accumulation_steps = 1\n",
        "gradient_checkpointing = True\n",
        "max_grad_norm = 0.3\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 0.001\n",
        "optim = \"paged_adamw_32bit\"\n",
        "lr_scheduler_type = \"constant\"\n",
        "max_steps = -1\n",
        "warmup_ratio = 0.03\n",
        "group_by_length = True\n",
        "save_steps = 25\n",
        "logging_steps = 5\n",
        "max_seq_length = None\n",
        "packing = False\n",
        "device_map = {\"\": 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-J5p5KS_MZY"
      },
      "source": [
        "#Load Datasets and Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "51fe372773894fd884a59c0b250fa9df",
            "32f49e7b9b704bc9813616b8c0beeb76",
            "32f9cf6737c24ab0bf74e4ac55e1b85f",
            "6c0cd5b7eb464abf9a63594a5fbdfbfa",
            "21aa5c3dc9804902933e64edbd02b429",
            "9a3a76dff0df4ee09cdfe599ec7da7d5",
            "c7cbd98d40ac45ddbeee90a44fc722db",
            "2a86e006a1b84df4bb1b62422dd274d7",
            "883cf300966942088acdacbacaed759b",
            "59bb2b4030f84fcb9b46f6c96e1f142e",
            "0176a3dab2be4553a1ba8165b40c0255",
            "93fc39db30c846d199bd3dfc01de9a6b",
            "e1634695d9c94c48882615c3bdeee8f9",
            "06ec895dfe0c44908c4e967bf930bfc0",
            "cda5ef8eb7e0476bb34536f811ecfcce",
            "020026de97e94b5a8a17bd7d62779ffc",
            "2f3ace2a15884501b6560d4934b4657b",
            "6112864ff60c41b29aebdb233f5c16b0",
            "62e95816b9e743d79655c0c663b195d1",
            "9d5f5bb29c17489a9d03fcf0a7acc1dd",
            "02cdec2f4c654d36a8b43edc2ed799e7",
            "51e55c91aecb4c5b8bd9cd1177b3fc34",
            "2f64918a98e24fd598500c2a112536e2",
            "c71a553e99a3433eb03356f88d8eca8a",
            "b3697c4e81f24695ab21a287eb1bdc5d",
            "39772a1129a9409b89b2d39c0317fdf0",
            "8fb0425962c546829b6a6404665cbf48",
            "dd705d620eb740568ad22285ce44c633",
            "585e7653ca984c41973083c3b49eaeb6",
            "a983b8ac01e6435f84050b137855c720",
            "dd8334e301674854b6dd8d76026cbdd9",
            "0be7a9def12d4c9d9a7fd7daef3a9c58",
            "b2261aee99b243d9ad9fad1fa1dd4b1a"
          ]
        },
        "id": "qf1qxbiF-x6p",
        "outputId": "31f9f503-ce8e-475e-9f68-244d8a0f2e29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51fe372773894fd884a59c0b250fa9df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93fc39db30c846d199bd3dfc01de9a6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/511 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f64918a98e24fd598500c2a112536e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/57 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='121' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [121/128 42:40 < 02:30, 0.05 it/s, Epoch 0.94/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.730200</td>\n",
              "      <td>2.886348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.699400</td>\n",
              "      <td>2.713974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.500100</td>\n",
              "      <td>2.561215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.465800</td>\n",
              "      <td>2.408849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.012100</td>\n",
              "      <td>2.268775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.345300</td>\n",
              "      <td>2.171365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.874500</td>\n",
              "      <td>2.117732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.120100</td>\n",
              "      <td>2.087240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>2.171600</td>\n",
              "      <td>2.070149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.908700</td>\n",
              "      <td>2.040256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.736000</td>\n",
              "      <td>2.025035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.115100</td>\n",
              "      <td>2.015980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.526400</td>\n",
              "      <td>2.014095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.995900</td>\n",
              "      <td>2.006722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>2.025600</td>\n",
              "      <td>1.994861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.872900</td>\n",
              "      <td>1.985011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.593200</td>\n",
              "      <td>1.979729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.225400</td>\n",
              "      <td>1.986357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.244100</td>\n",
              "      <td>1.977417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.129700</td>\n",
              "      <td>1.975325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>1.997000</td>\n",
              "      <td>1.966032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.780100</td>\n",
              "      <td>1.956343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>1.579000</td>\n",
              "      <td>1.949533</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/8 00:18 < 00:45, 0.11 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "train_dataset = load_dataset('json', data_files='/content/train.jsonl', split=\"train\")\n",
        "valid_dataset = load_dataset('json', data_files='/content/test.jsonl', split=\"train\")\n",
        "\n",
        "# Preprocess datasets\n",
        "#train_dataset_mapped = train_dataset.map(lambda examples: {'text': [f'[INST] <<SYS>>\\n{system_message.strip()}\\n<</SYS>>\\n\\n' + prompt + ' [/INST] ' + response for prompt, response in zip(examples['prompt'], examples['response'])]}, batched=True)\n",
        "#valid_dataset_mapped = valid_dataset.map(lambda examples: {'text': [f'[INST] <<SYS>>\\n{system_message.strip()}\\n<</SYS>>\\n\\n' + prompt + ' [/INST] ' + response for prompt, response in zip(examples['prompt'], examples['response'])]}, batched=True)\n",
        "# Preprocess datasets\n",
        "def format_data(example):\n",
        "    formatted_text = f'[INST] <<SYS>>\\n{system_message.strip()}\\n<</SYS>>\\n\\n{example[\"prompt\"]} [/INST] {example[\"response\"]}'\n",
        "    return {'text': formatted_text}\n",
        "\n",
        "# Aplicar formateo a los datasets\n",
        "train_dataset_mapped = train_dataset.map(format_data, batched=False)\n",
        "valid_dataset_mapped = valid_dataset.map(format_data, batched=False)\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "# Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"all\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=5  # Evaluate every 20 steps\n",
        ")\n",
        "# Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset_mapped,\n",
        "    eval_dataset=valid_dataset_mapped,  # Pass validation dataset here\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        ")\n",
        "trainer.train()\n",
        "trainer.model.save_pretrained(new_model)\n",
        "\n",
        "# Cell 4: Test the model\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "prompt = f\"[INST] <<SYS>>\\n{system_message}\\n<</SYS>>\\n\\nWrite a function that reverses a string. [/INST]\" # replace the command here with something relevant to your task\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
        "result = pipe(prompt)\n",
        "print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6fux9om_c4-"
      },
      "source": [
        "#Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hxQ_Ero2IJe"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "prompt = f\"[INST] <<SYS>>\\n{system_message}\\n<</SYS>>\\n\\nexplain to me the steps for a new hire in the company. [/INST]\" # replace the command here with something relevant to your task\n",
        "num_new_tokens = 100  # change to the number of new tokens you want to generate\n",
        "\n",
        "# Count the number of tokens in the prompt\n",
        "num_prompt_tokens = len(tokenizer(prompt)['input_ids'])\n",
        "\n",
        "# Calculate the maximum length for the generation\n",
        "max_length = num_prompt_tokens + num_new_tokens\n",
        "\n",
        "gen = pipeline('text-generation', model=model, tokenizer=tokenizer, max_length=max_length)\n",
        "result = gen(prompt)\n",
        "print(result[0]['generated_text'].replace(prompt, ''))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko6UkINu_qSx"
      },
      "source": [
        "#Merge the model and store in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgKCL7fTyp9u"
      },
      "outputs": [],
      "source": [
        "# Merge and save the fine-tuned model\n",
        "from google.colab import drive\n",
        "import torch\n",
        "\n",
        "# Libera toda la memoria caché no utilizada\n",
        "torch.cuda.empty_cache()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/llama-2-7b-custom\"  # change to your preferred path\n",
        "\n",
        "# Reload model in FP16 and merge it with LoRA weights\n",
        "try:\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        low_cpu_mem_usage=True,\n",
        "        use_cache=False,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=device_map,\n",
        "    )\n",
        "    model = PeftModel.from_pretrained(base_model, new_model)\n",
        "    model = model.merge_and_unload()\n",
        "    print(\"Modelo cargado y combinado con éxito\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"No se pudo cargar el modelo debido a un error de memoria: {e}\")\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Reload tokenizer to save it\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# Save the merged model\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-dFdE5zWGO"
      },
      "source": [
        "# Load a fine-tuned model from Drive and run inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg6nHPsLzMw-"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/llama-2-7b-custom\"  # change to the path where your model is saved\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBK2aE2KzZ05"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "prompt = \"What is 2 + 2?\"  # change to your desired prompt\n",
        "gen = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "result = gen(prompt)\n",
        "print(result[0]['generated_text'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0176a3dab2be4553a1ba8165b40c0255": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "020026de97e94b5a8a17bd7d62779ffc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02cdec2f4c654d36a8b43edc2ed799e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ec895dfe0c44908c4e967bf930bfc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e95816b9e743d79655c0c663b195d1",
            "max": 511,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d5f5bb29c17489a9d03fcf0a7acc1dd",
            "value": 511
          }
        },
        "0be7a9def12d4c9d9a7fd7daef3a9c58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21aa5c3dc9804902933e64edbd02b429": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a86e006a1b84df4bb1b62422dd274d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f3ace2a15884501b6560d4934b4657b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f64918a98e24fd598500c2a112536e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c71a553e99a3433eb03356f88d8eca8a",
              "IPY_MODEL_b3697c4e81f24695ab21a287eb1bdc5d",
              "IPY_MODEL_39772a1129a9409b89b2d39c0317fdf0"
            ],
            "layout": "IPY_MODEL_8fb0425962c546829b6a6404665cbf48"
          }
        },
        "32f49e7b9b704bc9813616b8c0beeb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a3a76dff0df4ee09cdfe599ec7da7d5",
            "placeholder": "​",
            "style": "IPY_MODEL_c7cbd98d40ac45ddbeee90a44fc722db",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "32f9cf6737c24ab0bf74e4ac55e1b85f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a86e006a1b84df4bb1b62422dd274d7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_883cf300966942088acdacbacaed759b",
            "value": 2
          }
        },
        "39772a1129a9409b89b2d39c0317fdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0be7a9def12d4c9d9a7fd7daef3a9c58",
            "placeholder": "​",
            "style": "IPY_MODEL_b2261aee99b243d9ad9fad1fa1dd4b1a",
            "value": " 57/57 [00:00&lt;00:00, 441.64 examples/s]"
          }
        },
        "51e55c91aecb4c5b8bd9cd1177b3fc34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51fe372773894fd884a59c0b250fa9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32f49e7b9b704bc9813616b8c0beeb76",
              "IPY_MODEL_32f9cf6737c24ab0bf74e4ac55e1b85f",
              "IPY_MODEL_6c0cd5b7eb464abf9a63594a5fbdfbfa"
            ],
            "layout": "IPY_MODEL_21aa5c3dc9804902933e64edbd02b429"
          }
        },
        "585e7653ca984c41973083c3b49eaeb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59bb2b4030f84fcb9b46f6c96e1f142e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6112864ff60c41b29aebdb233f5c16b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62e95816b9e743d79655c0c663b195d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c0cd5b7eb464abf9a63594a5fbdfbfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59bb2b4030f84fcb9b46f6c96e1f142e",
            "placeholder": "​",
            "style": "IPY_MODEL_0176a3dab2be4553a1ba8165b40c0255",
            "value": " 2/2 [01:11&lt;00:00, 32.70s/it]"
          }
        },
        "883cf300966942088acdacbacaed759b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fb0425962c546829b6a6404665cbf48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93fc39db30c846d199bd3dfc01de9a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1634695d9c94c48882615c3bdeee8f9",
              "IPY_MODEL_06ec895dfe0c44908c4e967bf930bfc0",
              "IPY_MODEL_cda5ef8eb7e0476bb34536f811ecfcce"
            ],
            "layout": "IPY_MODEL_020026de97e94b5a8a17bd7d62779ffc"
          }
        },
        "9a3a76dff0df4ee09cdfe599ec7da7d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5f5bb29c17489a9d03fcf0a7acc1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a983b8ac01e6435f84050b137855c720": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2261aee99b243d9ad9fad1fa1dd4b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3697c4e81f24695ab21a287eb1bdc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a983b8ac01e6435f84050b137855c720",
            "max": 57,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd8334e301674854b6dd8d76026cbdd9",
            "value": 57
          }
        },
        "c71a553e99a3433eb03356f88d8eca8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd705d620eb740568ad22285ce44c633",
            "placeholder": "​",
            "style": "IPY_MODEL_585e7653ca984c41973083c3b49eaeb6",
            "value": "Map: 100%"
          }
        },
        "c7cbd98d40ac45ddbeee90a44fc722db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cda5ef8eb7e0476bb34536f811ecfcce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02cdec2f4c654d36a8b43edc2ed799e7",
            "placeholder": "​",
            "style": "IPY_MODEL_51e55c91aecb4c5b8bd9cd1177b3fc34",
            "value": " 511/511 [00:00&lt;00:00, 594.60 examples/s]"
          }
        },
        "dd705d620eb740568ad22285ce44c633": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd8334e301674854b6dd8d76026cbdd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1634695d9c94c48882615c3bdeee8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f3ace2a15884501b6560d4934b4657b",
            "placeholder": "​",
            "style": "IPY_MODEL_6112864ff60c41b29aebdb233f5c16b0",
            "value": "Map: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
